Using the notes, start generating this projects from scratch in C++. Note that it should be totally self contained in a giant single file called makocode.cpp, pulling in literally no libraries of any kind.
Create a makefile and a singular test file that encodes random data with the simplest default settings, then decodes it and verifies the output is the same
The output format of encode, and input to decode, should be in ppm (portable pixmap format). The test file should just be test.cpp
Rename test_runner to just test.
I didn't see you had selftest already in makocode.cpp. Remove test.cpp, rename selftest to test and make sure it's writing random data out too.
Have an option for test to leave the test files for visual inspection. The default is still to remove them
Make the default encode/decode work against black and white with no shades. There should be an option to specify color channels and shade channels, however.
Add 3 colors versus 3 shades in the test, so 9 output ppm files to test in total
Make clean needs to remove all the test files. I just ran it and there are some remaining, take a look
The 2 channel option should be CMY (cyan magenta yellow) looks like you've done different colors, maybe red and blue. Make it CMY.
2 channels now looks like RGB, not CMY. Fix it. Also remove the --keep option, just always keep by default. Make clean already does the deleting so it's extraneous.
Ok when I ./makocode test, the c2_s1 is clearly RGB on my Mac. That should only have the color Cyan, Magenta, and Yellow. And white of course. That file has also red, blue, and green - which is incorrect. Fix this.
Ok once again look at encoded_c2_s1.ppm, there are obviously red pixels here. It should only be printing out cyan, magenta, and yellow, and white. Do not print out red for color channels 2.
Excellent! However you simply need to do shades 2 and 3 in the test as well.
Make test should generate shades 2 and 3 for color channel 2. It does so for 1 and 3. Fix it, there should be 9 ppms after this.
The output ppm for colors=2 shades=2 or 3 is wrong. If it were correct, it would at least have cyan, magenta, yellow, and white in there along with intermediate shades. It does not. Fix it.
Add LZW compression and decompression in the encode/decode
Can you completely remove the headers like metadata, fiducial, payload, address, etc? Just put the straight data starting at byte 0, there are no options or metadata.
But keep LZW I mean
Drop the comment tag as you suggest, also fix the initial comment to summarize the code correctly as it's somewhat working now.
Remove all #MAKOCODE * comments from the PPM
Round trip mismatch when running test
Fix the makocode.cpp comment to reflect the functionality now, it has changed. Remove NOTES.md mentions now, it's not a prototype anymore.
Remove shade channels completely
These output ppm's have shades. I want color=1 to be only black and white. Color=2 is only cyan, magenta, and yellow. Color=3 is RGB CMY and white/black.
Color=2 is CMY, and white - I mean.
I ran make clean but there are some files remaining, make sure they're all cleaned up
In colors=3 RGBCMYWB setting, I see structure in the output file - there is 1 column of white every 4th column. If this were perfectly compressed, like the colors=1 and 2 examples, I would not see the columns. Can you either explain it or fix it?
Whoa don't switch to python. Leave it as a single cpp file.
I'm curious why the filesize is approx the same after. If these were white columns making up 25% of the file, that implies a pretty bad compression no?
Add a page width, height and dots per inch. Default to A4 paper sizes and 300 DPI. If the file would span multiple pages, print out multiple ppm files. The decoder must read in multiple files as well, and should support * syntax, e.g. makocode decode scanned*.ppm . Make sure the test for each of c=1, 2, 3 tests exactly 2 full pages of data.
Make the pagewidth and height arguments not be in inches, but pixels instead. Remove density (dpi) and inches completely.
print an optional user provided title string at the bottom of the page, with an argument for font size. Valid characters are alphanumeric only.
Make the title print as small as possible with no margin, e.g. 5x5 pixels on the page, starting from the left. Use only 1 column, 1x5, as a space between characters.
I see 5x7 gylphs in the code. Print those as small as possible, 5x7 pixels total, with 1 white column for a space, at the bottom. Currently it prints huge text.
Write the file out with default name being the UTC timestamp (and page num as before), whether it's one or multiple pages. E.g. don't pipe the output out, always write the file. Right now looks like the single page is a pipe, while multiple pages is a write.
Can you add to the characters allowed in the title: lower and upper alpha, numeric, and the most common special characters - like space, !@#$%^&*(){}[]:\";'<>?,./`~|\\
Also add -=_+
Can you make lowercase a-z characters work too?
I want the following additional options for printing text in the bottom row: Filename (needs to be an input - currently it's read from stdin I think and I just want it read from a file) and page count (e.g. Page 2/10) only if there's more than one page. So filename and page count should be displayed by default, and the previous arbitrary title field should not be displayed unless entered. There's also a title-font field that should be renamed font-size and applies to all these fields.
Add an option to not display the filename in the footer. Additionally, make the optional title come before the filename.
Add a page count to the footer, with an option to remove it, that displays like 1/1 or 3/7, e.g. current page / total pages
Add error correcting codes, e.g. Reed Solomon, with an argument for the percent redundancy. E.g. 0.10 means that the data is covered 10%, and the output is thus 10% larger. 2.00 means the output is triple the size of the data, as there are 2x as much ECC as data.
Previously you had written some ECC code, parts of the calculation might be right but I'm skeptical because the ECC lines are horizontal black lines, which couldn't carry any useful data.
Can you invert white and black in the color channel 1 image? Black should be 1, and White should be 0 - essentially.
Write me a new test case that encodes, then randomly flips some bits, then decodes, to check the ECC works as expected.
Continue working to fix the fact that ./makocode test --ecc=0.2 doesn't work yet.
The error correction algorithm is still wrong. If I encode and then change the ppm file to modify the very first 255 255 255 to be 0 0 0, it does not decode correctly. I would expect ECC to fix that, then decompress, and return the original input.
It's still not quite there. I modified the first few hundred bits from 255 to 0, and it's giving decode: parse failure again
How do I get it to decode multiple pages?
I've been running multiple tests and it's not looking good for error correction. I tried encoding, changing 255 to 0 for single random pixels, then decoding, and the output is not the same as the input. I'd also like a warning printed if the error detection could not return the original, reed-solomon should be able to not just correct  but also to detect.
Still not working. Look at my out.txt, after modifying 5 pixels from 255 to 0 the line 4346 modified le_ to slot =, that's totally wrong.
I want you to implement data shuffling after encoding, compressing, and ecc. You can use a simple algorithm like fisher yates with a pcg-64 seed-0 so the ordering is well-known and consistent without storing information about it. This is so that the error correction applies spatially across pages rather than being local. Eventually it would help pages being removed completely from the sample but no need to worry about that for now.
Add optional ChaCha20-Poly1305 encryption, after compression but before shuffling. If no password is supplied at encoding or decoding, it's not assumed to be encrypted. If a password is supplied in either case, it's attempts to do encryption/decryption. If possible print out if the attempt fails with the given password.
make c++ -std=c++17 -Wall -Wextra -pedantic -O2 makocode.cpp -o makocode makocode.cpp:5800:66: error: too few arguments to function call, expected 4, have 2 5800 |     if (!validator.parse(corrupted.data, (usize)encoded_bit_count)) { |          ~~~~~~~~~~~~~~~                                         ^ makocode.cpp:2608:10: note: 'parse' declared here 2608 |     bool parse(u8* data, usize size_in_bits, const char* password, usize password_length) { |          ^     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1 error generated.  make: *** [makocode] Error 1
I encoded with password=password, decoded with password=password and it didn't work. Can you write a test case and fix it?
./makocode encode --input=makocode.cpp --page-width=500 --page-height=500 --ecc=0.5 --password=password ; ./makocode decode 2025* --password=password > out.txt ; decode: ECC could not repair the payload ; # Maybe check your test cases. Password and ecc should be run in the suite on/off when makocode test is run, they're not optional.
Accept multiple input files or a directory, and now don't require an output file argument. I want you to encode the filename(s) into the body and/or directory nested structure, and then when I run decode you will recreate it at the output-path directory, which defaults to the current directory, in the same nested folder structure as the input (or as multiple files), creating subdirectories recursively as needed.
I want you to create a series of tests that encodes and image and then distorts the image as if it were scanned. The purpose of this program is to print and then scan the image, so before I do that simulate it with new tests essentially. For example scanning will need to be 1-2x the printing resolution or greater, so if it's 1.3x and rotated with wavy distortions, those are good test cases. Then fix the test cases by actually performing the image recognition algorithms required.
Keep going, sorry I cleaned the env. Fix make with any/all suggestions you have
Keep going, make test fails still
I want you to fix the decoding algorithm to handle the case where the pixels could be 1x, 2x, 3x, etc. - e.g. multiple integer sizes. This may involve some rudimentary edge detection. Do NOT handle 1.5x, etc, which involves complicated computer vision algorithm. Keep it as simple as you can. You need to add test cases and keep iterating until they pass.
Fix the tests so that you only need 1 page per test - except for a single test for black and white that tests 2 pages.
I may be mistaken but it appears you did not actually generate a test case that scales up the encoded image and then decodes. None of the PPM files have pixels that are 2x2 or 3x3, which is what I would expect. Please do so, re-run the tests and confirm the detection logic works as expected.
I have provided you the source code of optar under optar/, I want you to just tell me all the steps it takes to get a scanned image turned into a clean data so we can copy its techniques in makocode.
I don't want golay, I like reed-somolomon which is what you previously wrote in makocode. Can you come up with a list of instructions to feed back to you, maybe in different sessions, that will implement all of the image recognition parts of optar into makocode? I want you to write tests for each case and instruct yourself to self feedback loop between test and source code until you get it right. Write them in a way that each result is useful. Right now makocode only works with scaling (2x, 3x) so that logic might need to be torn down too.
- Introduce an image_buffer module (new .cpp/.h or split from makocode.cpp) that can read 8‑bit grayscale PNG into a linear buffer, applying gamma like optar/unoptar.c:1496–1572; add unit tests with tiny hand-made PNG\n    fixtures (clean page, noisy page, wrong depth) to confirm gamma handling and rejection paths.\n  - Port the histogram/cut-level analysis from optar/unoptar.c:179–263 into the new module; drive it with tests that feed synthetic histograms (bimodal, skewed, low-contrast) and assert the chosen thresholds.\n  - Create a CLI test hook (e.g. makocode test-scan-basic) that loads a PNG, dumps the computed thresholds, and fails when they drift from golden JSON recorded in the fixture directory; iterate test→code until\n    repeatable.
please make sure image buffer is moved to mskocode, one file only please
I don't see a new test case that would check what you've written, please continue
Did you say this reads PNG files? I only want to read/write ppm
Regenerate the test fixture as ppm then, remove anything png related in makocode or tests
Now I want you to generate those text fixtures, golden, anything else in makocode.cpp as needed at runtime, and make clean should delete them.
Can you make all the test files output under a test/ directory? Then make clean can just delete that test/ directory rather than *ppm *bin
How are you using those text fixtures?
Can you generate a test case where an entire encoded image has the distortions from these 3 test fixtures applied across it? I want to see fuzzy ppm images essentially as if they were scans.
I ran make test, I didn't see any test/scan_*.ppm. Did you actually write it?
Implement them
Can you make each test case print out its own name to the console? I see debug logs right now but it's hard to tie them to what test they ran
Are you actually decoding the scan files, or just writing them out?
In the most recent commit, you began image recognition using techniques from optar. You wrote out scanned files. Now I want you to modify the tests to read back in not just the clean files, but also the scanned files in the output. Continue a feedback loop of fixing the source code and modifying the tests as needed. So far the scanned files you generated look great, but I think you'll find it difficult to get the source code right so also don't be afraid to relax your scanning requirements so they don't look so distorted. You can reference unoptar.c as need for inspiration. Don't forget, all code must live in the single file makocode.cpp.
Can you rename the test artifacts so they match alphabetically? For example, scan_s1_c1_p02_x2.bin should encode to scan_s1_c1_p02_x2.ppm and then should decode to scan_s1_c1_p02_x2_decoded.ppm
I still see decode_...bin, rather than ..._decoded.bin. *Also decoded.ppm doesn't make sense. It should be for each test: title.bin, -> title_encoded.ppm -> (possibly) title_scan.ppm -> title_decoded.bin, then compare the title_encoded.bin and title_decoded.bin
Close, you need to name anything that is 1x1 pixels (unmodified) as data_..., anything that is scaled like 2x2 or 3x3 pixels as scaled_..., and anything that is a scan (like the fixtures applied, a fuzzy image) as scan_... . Try to use descriptive prefixes. All of these test data are named \"scan_...\" but they're not scans, they're 1x1 pixel images with no modifications applied.
Ok now you need to actually apply the data fixture modifications to the scan_ images. They're 1x1 pixels. Apply the modification, it may break the test right now because your decoding is probably not good enough, which is ok.
Run make test, iterate and fix the code to get image recognition to work for these messy images until you have the source code working.
Can you add data_s1_c*_p01_encoded.ppm for colors 1 2 and 3 into the README as an example of what the barcode looks like? Not sure if MD supports ppm so you might need to convert them to PNG. Put them in an images/ directory.
Can you make those images 3 times their current size?
In github the same. Can you make them back to 1x1 pixels per data point, but scale up in markdown?
I want the README images to look clean, github looks like it's using some kind of interpolation when sizing it up. Can you make the images be clean 3x3 pixel versions of themselves? No interpolation. I want exactly 1, 4, or 8 colors in the images, no fuzziness.
